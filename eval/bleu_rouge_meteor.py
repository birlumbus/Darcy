import nltk
from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction
from nltk.translate.meteor_score import meteor_score


def lcs_length(x, y):
    """
    Compute the length of the longest common subsequence between two token lists.
    """
    m, n = len(x), len(y)
    dp = [[0] * (n + 1) for _ in range(m + 1)]
    for i in range(m):
        for j in range(n):
            if x[i] == y[j]:
                dp[i+1][j+1] = dp[i][j] + 1
            else:
                dp[i+1][j+1] = max(dp[i+1][j], dp[i][j+1])
    return dp[m][n]


def rouge_l(candidate_tokens, reference_tokens):
    """
    Compute ROUGE-L F1 score between candidate and reference tokens.
    """
    lcs = lcs_length(candidate_tokens, reference_tokens)
    if lcs == 0:
        return 0.0
    precision = lcs / len(candidate_tokens)
    recall = lcs / len(reference_tokens)
    if precision + recall == 0:
        return 0.0
    f1_score = (2 * precision * recall) / (precision + recall)
    return f1_score


def bleu_rogue_meteor(references, candidate):
    """
    Compute BLEU, ROUGE-L, and METEOR scores for the candidate text against a list of references.
    
    Parameters:
        references (list): List of reference strings.
        candidate (str): Generated candidate string.
        
    Returns:
        tuple: (BLEU score, ROUGE-L score, METEOR score)
    """

    # tokenization using whitespace splitting
    references_tokens = [ref.split() for ref in references]
    candidate_tokens = candidate.split()
    
    # BLEU score with smoothing (to handle cases with few overlaps)
    smoothie = SmoothingFunction().method1
    bleu = sentence_bleu(references_tokens, candidate_tokens, smoothing_function=smoothie)
    
    # ROUGE-L: compute for each reference and select the maximum score
    rouge_scores = [rouge_l(candidate_tokens, ref_tokens) for ref_tokens in references_tokens]
    rouge = max(rouge_scores) if rouge_scores else 0.0
    
    # preliminary to METEOR testing (only required once)
    # nltk.download('wordnet')
    
    # METEOR score (nltk expects references as a list of strings)
    meteor = meteor_score([ref.split() for ref in references], candidate.split())
    
    return bleu, rouge, meteor


# for testing directly
if __name__ == "__main__":
    # example ref texts
    references = [
        "Your list of the common extent of accomplishments has too much truth.",
        "The word is applied to many a woman who deserves it no otherwise than by netting a purse or covering a screen; but I am very far from agreeing with you in your estimation of ladies in general.",
        "I cannot boast of knowing more than half-a-dozen in the whole range of my acquaintance that are really accomplished."
    ]
    # candidate text generated by a model
    candidate = "I do not like to be the first to break silence with a stranger whom I only saw once before; and if I do speak, I shall probably make my words too stiff, and my manner too stately and distant; so if you will be so good, cousin, as to tell me, first, who are these people with you?--for I did not want to look at the woman, because I was half ashamed of the dress she wore. I had never seen any one dressed so."
    
    bleu, rouge, meteor = bleu_rogue_meteor(references, candidate)
    print(f"BLEU: {bleu:.4f}")
    print(f"ROUGE-L: {rouge:.4f}")
    print(f"METEOR: {meteor:.4f}")
